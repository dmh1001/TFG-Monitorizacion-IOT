
\apendice{Documentación técnica de programación}

\section{Introducción}

En el siguiente anexo se describe la documentación técnica del programa, se detalla cómo está estructurado, cómo realizar la correcta instalación y configuración del mismo, así como la batería de pruebas realizadas.

\section{Estructura de directorios}

\nombrePrograma se instala en la carpeta \textit{/usr/bin/} dentro un servidor Ubuntu. El programa consta de un script principal que mediante un daemon se ejecuta constantemente en segundo plano. Por cada ciclo de ejecución (por defecto es de un minuto) se descargan los datos en bruto desde PRTG y se almacenan en la carpeta \textit{/usr/bin/Monitorizacion\_IOT/Gestion\_datos/logs/}. De ahí son procesados y guardados temporalmente en la carpeta

\textit{/usr/bin/Monitorizacion\_IOT/Gestion\_datos/TempData\_sensores/} 

Tras realizar las comparaciones necesarias y asegurarse que no se van a subir datos repetidos a Elasticsearch se almacenan los datos finales en la carpeta \textit{/usr/bin/Monitorizacion\_IOT/Gestion\_datos/load} desde la cual se suben a la base de datos.

Al realizar el entrenamiento o la predicción de los sensores se cargan los modelos correspondientes a dichos sensores, estos se encuentran almacenados en la carpeta \textit{/usr/bin/Monitorizacion\_IOT/Prediccion/modelos/}. 

Cuando se realiza el entrenamiento de un modelo este devuelve los datos generados y los almacena en

\textit{/usr/bin/Monitorizacion\_IOT/Gestion\_datos/TempData\_entrenamiento/}.

A la hora de predecir también se devuelven los datos generados, los cuales se almacenan en 

\textit{/usr/bin/Monitorizacion\_IOT/Gestion\_datos/TempData\_prediccion/}

por último, en la carpeta
\textit{/usr/bin/Monitorizacion\_IOT/Utilidades/} se encuentran diversas funciones de utilidad. 

\begin{figure}[h]
	\dirtree{%
		.1 /.
		.2 usr.
		.3 bin.
		.4 Monitorizacion\_IOT.
		.5 Gestion\_datos.
		.7 load.
		.7 logs.
		.7 TempData\_sensores.
		.7 TempData\_entrenamiento.
		.7 TempData\_prediccion.
		.5 Prediccion.
		.7 modelos.
		.5 Utilidades.
	}
	\caption{Directorios del proyecto}
	\label{directoriosdelproyecto}
\end{figure}

\newpage
\section{Manual del programador}

El manual del programador tiene como objetivo ayudar a todas aquellas personas que vayan a trabajar con este proyecto.
\subsection{Entorno de desarrollo}

Para la realización de este proyecto se necesita tener instalados los siguientes programas y dependencias:

\begin{itemize}
    \item Python 3: versión 3.8.10 
    \item Elasticsearch: versión 7.4
    \item Kibana: versión 7.14.1
    \item Logstash: versión 7.14.1
    \item Openjdk-11-jre-headless: versión 11.0.11
\end{itemize}
bibliotecas python:
\begin{itemize}
    \item River versión 0.71
    \item Pandas: versión 1.3.2
    \item Elasticsearch: versión 7.14.0
    \item Numpy: versión 1.21.2
\end{itemize}

\subsection{Archivos}
A continuación, se mostrarán todos los ficheros que conforman el programa así como una breve descripción:

\begin{itemize}
    \item \textbf{Monitorizacion\_IOT.sh}: Este es el script principal de la aplicación el cual está sujeto a un daemon, de tal forma que se repite en bucle cada minuto descargando los datos de PRTG, subiéndolos a Elasticsearch, realizando el entrenamiento y la predicción de cada sensor.
    
    \item \textbf{/Gestion\_datos/Descargar\_data.sh}: Es el script que se encarga de descargar los datos de PRTG, transformar dichos datos y subirlos a Elasticsearch.
    
    \item \textbf{/Gestion\_datos/Borrar\_datos\_predicciones.sh}: Debido a que para cada sensor se repite la predicción cada minuto y se suben los resultados a Elasticsearch es necesario borrar la predicción anterior para que siempre se pueda visualizar la predicción actualizada, este script hace exactamente eso.
    
    \item \textbf{/Gestion\_datos/Load\_sensor\_data.sh}: Este script se encarga de enviar línea por línea de un fichero a Logstash para poder ser enviado a Elasticsearch.
    
    \item \textbf{/Gestion\_datos/Extractor.py}: En este fichero se encuentra la clase encargada de la descarga de datos de Elasticsearch.
    
    \item \textbf{/Predicciones/Crear\_modelo.py}: En este fichero el usuario puede configurar y crear un modelo para un sensor.
    
    \item \textbf{/Predicciones/Modelo.py}: En este fichero se encuentran las clases que corresponden a todos los modelos.
    
    \item \textbf{/Predicciones/Persistencia\_modelo.py}: En este fichero se encuentra la clase que permite guardar en disco y cargar cada modelo.
    
    \item \textbf{/Predicciones/Realizar\_entrenamiento.py}: Es el fichero encargado de la realización del entrenamiento del modelo de un sensor, se carga el modelo correspondiente al sensor, se descargan los últimos datos subidos a Elasticsearch y se realiza en entrenamiento del modelo y finalmente se guarda el modelo en disco.
    
    \item \textbf{/Predicciones/Realizar\_prediccion.py}: Es el fichero encargado de realizar la perdición de un sensor, se carga el modelo correspondiente al sensor que se desea predecir y se realza la perdición a partir de la fecha actual y tantos instantes de tiempo cómo este especificado en el fichero principal, Monitorizacion\_IOT.sh.
    
    \item \textbf{/Utilidades/campos.py}: En este fichero se encuentra una clase de enumeración donde se encuentran los tres tipos de campos que se suben a Elasticsearch.
    \begin{itemize}
        \item \textbf{VALOR}: Corresponde al valor real recogido por el sensor.

        \item \textbf{PREDICCION}: Corresponde al valor de la predicción 
        \item \textbf{ENTRENAMIENTO}:Corresponde al valor del entrenamiento.
    \end{itemize}
    
    \item \textbf{/Utilidades/Generador\_lineas.py}: En este fichero se encuentra la clase encargada de generar las líneas de texto en un formato específico para poder ser procesadas por Logstash. 
    
    \item \textbf{/Utilidades/Tratamiento\_sensor\_data.py}: En este fichero se encuentra la clase encargada de tratar con los datos de los sensores, permite leer ficheros JSON y transformarlos.
    
    \item \textbf{/Utilidades/Transformar\_data.py}: Es el fichero encargado de transformar los ficheros JSON con los datos procedentes de PRTG en un fichero apto para ser procesado por Logstash. 
    
\end{itemize}

\subsection{Modelos}

La biblioteca de Python, River, facilita dos tipos de modelos para series temporales permitiendo realizar el entrenamiento de manera incremental con un data stream procedente de los sensores así cómo realizar una predicción de su comportamiento.

Pese a que solo estén implementados en la aplicación dos tipos de modelos está preparada para que se pueda implementar nuevos tipos de modelos de diversas bibliotecas.

\subsubsection{Implementar nuevos modelos}

\nombrePrograma es flexible a la implementación de nuevos modelos de incremental learning, para crear un nuevo modelo se ha de acceder a la carpeta donde se ha instalado el programa y editar el fichero \textit{/Predicciones/Modelo.py}, en este fichero se puede ver la clase abstracta \textit{Modelo} la cual implementa cuatro métodos abstractos:
\begin{itemize}
    \item \textbf{inicializar(self)}: El método encargado de inicializar el modelo, implementando el algoritmo deseado.
    
    \item \textbf{cargar(self, model)}:  El método encargado de cargar el modelo.
    
    \item \textbf{entrenar(self, datos)}: El método encargado del entrenamiento del modelo a partir de una serie de datos
    \item \textbf{predecir(self, horizonte)}: El método encargado de realizar la predicción a futuro de un sensor a partir de un modelo ya entrenado.
\end{itemize}

Para crear un nuevo modelo se a de programar una nueva clase que herede de \textit{Modelo} e implemente estas cuatro funciones.

\section{Compilación, instalación y ejecución del proyecto}

En este apartado se mostrará cómo instalar \nombrePrograma. Para facilitar la utilización del programa se adjunta una máquina virtual 

\subsection{Configuración Ubuntu Server}

Para albergar el programa se utilizará una máquina virtual Ubuntu Server.

Antes de comenzar la instalación del programa se tiene que asegurar que estén instaladas las herramientas de red de Linux, las cuales ayudarán a conocer la IP del servidor, y con ella poder acceder al servidor de forma remota.


\begin{lstlisting}[frame=single] 
apt install net-tools
\end{lstlisting}

También es necesario comprobar la zona horaria del servidor y si es necesario cambiarla, se puede utilizar el siguiente comando:


\begin{lstlisting}[frame=single] 
dpkg-reconfigure tzdata
\end{lstlisting}

\subsection{Instalación \nombrePrograma}

Una vez instalado y configurado Ubuntu Server en una máquina virtual se puede proceder a la instalación de \nombrePrograma. Para ello es necesario tener descargado del repositorio \url{https://github.com/dmh1001/TFG-Monitorizacion-IOT} tanto el script \textit{install.sh} cómo el paquete Debian \textit{MonitorizacionIOT\_1.0\_all.deb}. Importante, a la hora de instalar el programa ambos ficheros se han de encontrar en un mismo directorio. 

Una vez se tenga estos ficheros en la máquina virtual se podrá comenzar la instalación, para mayor comodidad, asegurarse que se accede con el usuario \textit{root}, para ello se puede utilizar el siguiente comando:

\begin{lstlisting}[frame=single] 
sudo su
\end{lstlisting}

Para instalar el programa y sus dependencias sólo es necesario ejecutar el script \textit{install.sh} que instalará una serie de paquetes, cómo son Elasticsearch, Logstash, Kibana, bibliotecas de Python y el propio programa. 

\begin{lstlisting}[frame=single] 
bash install.sh
\end{lstlisting}

a continuación, se mostrará el código que realiza el instalador:

\begin{lstlisting}[frame=single] 
wget -qO - https://artifacts.elastic.co

/GPG-KEY-elasticsearch | sudo apt-key add -

echo "deb https://artifacts.elastic.co/packages/7.x

/apt stable main" 
| sudo tee -a /etc/apt/sources.list.d

/elastic-7.x.list

apt update

sudo apt-get install apt-transport-https

sudo apt install elasticsearch

sudo apt install kibana

sudo apt install logstash

sudo apt install openjdk-11-jre-headless

apt update && apt upgrade

sudo apt install python3-pip
pip3 install river
pip3 install pandas
pip3 install elasticsearch
pip3 install numpy

sudo dpkg -i 
--force-overwrite MonitorizacionIOT_1.0_all.deb

\end{lstlisting}

Este proceso se puede demorar unos minutos y es posible que pida la confirmación, por parte del usuario de la instalación de ciertos paquetes.

El instalador se encarga de instalar el paquete Debian que contiene los archivos del programa, el cual se instalará en la ruta \textit{/usr/bin/Monitorizacion-IOT/}. 

\subsubsection{Configuraciones}

El script también se encarga de configurar Elasticsearch, Kibana y Logstash así cómo iniciar los servicios.
Tras instalarse el paquete se realizan una serie de configuraciones sobre los servicios de Elasticsearch y Kibana, estás se hacen automáticamente si necesidad de la supervisión del usuario.

\textbf{Elasticsearch}

Se configura el archivo que se encuentra en la ruta:

/etc/elasticsearch/elasticsearch.yml

\textbf{Kibana}

El archivo de configuración se encuentra en la ruta:

/etc/kibana/kibana.yml
 
Se crea una carpeta y se le añaden permisos para guardar los logs que Kibana genere.
 
\begin{lstlisting}[frame=single]  

mkdir /var/log/kibana
chown -R Kibana:kibana /var/log/kibana/

\end{lstlisting}
 
 \subsubsection{Inicio de procesos}
 
 Tras instalar todos los paquetes y ficheros necesarios se inicializan los procesos:
 
 \textbf{Elasticsearch}
 
 \begin{lstlisting}[frame=single]  
  systemctl daemon-reload && 
  systemctl enable elasticsearch.service
  systemctl start elasticsearch
\end{lstlisting}
 
 
 \textbf{Kibana}
 
 \begin{lstlisting}[frame=single]  
systemctl daemon-reload && systemctl enable Kibana
systemctl start kibana
\end{lstlisting}
 
\textbf{Logstash}
 
\begin{lstlisting}[frame=single] 
systemctl daemon-reload && systemctl enable Logstash
systemctl start logstash

\end{lstlisting}
 
 Este es el último paso que realiza el instalador, a partir de aquí el resto de la configuración corre a cargo del usuario.
 
\subsection{Comprobación de procesos}

Es importante comprobar que los procesos funciones con normalidad y que estos estén activos 

\begin{lstlisting}[frame=single]  
systemctl status Monitorizacion_IOT

systemctl status elasticsearh
systemctl status kibana
systemctl status logstash
\end{lstlisting}

Si resulta que alguno de los componentes no se encuentra activos podemos reiniciar el servicio.

\begin{lstlisting}[frame=single]  
systemctl restart Monitorizacion_IOT

systemctl restart elasticsearh
systemctl restart Kibana
systemctl restart Logstash
\end{lstlisting}

\section{Pruebas del sistema}

\subsection{Pruebas de regresión}

A la hora realizar predicciones es extremadamente importante saber cómo de fiable es el modelo que se está utilizando por lo que realizar pruebas es completamente necesario.


\subsubsection{Datasets}
Debido a que no se posee históricos de los datos de los sensores y ya que PRTG sólo recopila datos cuando está conectado en un equipo en funcionamiento, los \textit{datasets} empleados para realizar las pruebas no son lo suficientemente extensos cómo para entrenar el modelo y que saque predicciones fidedignas. 

Por ello, se realizarán las pruebas con datos recogidos en intervalos de varias de horas y se comprobará cómo se comporta el algoritmo a corto plazo.

Para estas pruebas se usarán dos de los sensores, el que mide la presión de la tubería de agua y el que mide el consumo de la bomba de agua.

\begin{figure}[h]
	\centering
	\includegraphics[width=1.1\textwidth]{img/img_dataset2051.png}
	\caption{Dataset sensor de Presión Tubería de Agua}
	\label{img_prediccion_sensor2051}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=1.1\textwidth]{img/img_2052_trues.png}
	\caption{Dataset sensor Consumo de bomba de agua}
	\label{img_prediccion_sensor2051}
\end{figure}

\subsubsection{Métricas de regresión}

Las métricas de regresión dan un promedio de cuanto de acertadas están las predicciones obtenidas sobre el valor real. Para ello se utilizarán las siguientes métricas:

\textbf{MSE}

Mean Squared Error o MSE es una de las métricas más comunes en la evaluación de regresión. Mide el error cuadrado promedio de las predicciones.

Se calcula como el promedio de las diferencias al cuadrado entre los valores reales y los predichos.

\begin{equation*}
    MSE = \frac{1}{N} \cdot \sum_{i=1}^{N}(y_i - \hat{y}_i)^2
\end{equation*}

Al elevarse al cuadrado tiende a inflar errores grandes, por lo que cuanto mayor sea la diferencia entre la predicción y los valores reales mayor será el error.

\textbf{RMSE}

Root Mean Squared Error o RMSE es una extensión de MSE. Esta métrica calcula la raíz cuadrada de MSE, haciendo que las unidades de las métricas sean las mismas que las unidades de los valores originales.

\begin{equation*}
    RMSE = \sqrt{\frac{1}{N} \cdot \sum_{i=1}^{N}(y_i - \hat{y}_i)^2} 
\end{equation*}

Al elevar el MSE al cuadrado se deja de penalizar los errores grandes,

\textbf{MAE}

Mean Absolute Error o MAE al igual que RMSE las unidades de error coinciden con las unidades de los valores reales y predichos.

MAE no da más o menos peso a los diferentes tipos de error y las puntuaciones aumentan linealmente con el aumento del error.

Se calcula como el promedio del valor absoluto de la diferencia entre los valores reales y predichos.

\begin{equation*}
    MAE = \frac{1}{N} \cdot \sum_{i=1}^{N}|y_i - \hat{y}_i| 
\end{equation*}

\textbf{R2}

R2 es una métrica que calcula la bondad del modelo.

El mejor valor posible es 1, indicando una predicción perfecta y puede tomar valores negativos si la predicción es muy mala. 
\begin{equation*}
    R^2 = 1 - \frac{\sum(Y_i - \hat{y}_i)^2}{\sum(Y_i - \bar{y}_i)^2}
\end{equation*}


Para los siguientes test se utilizará el modelo SNARIMAX. Se realizan las pruebas con datos 
recopilados de siete días distintos, 

\subsubsection{Pruebas Sensor Consumo Bomba Agua}

\begin{figure}[h]
	\centering
	\includegraphics[width=1.1\textwidth]{img/img_2052_1.png}
	\caption{Consumo Bomba Agua en las fechas: 28/08/2021 - 29/08/2021}
	\label{img_prediccion_sensor2051}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=1.1\textwidth]{img/img_2052_4.png}
	\caption{Consumo Bomba Agua en las fechas: 25/08/2021 - 26/08/2021}
	\label{img_prediccion_sensor2051}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=1.1\textwidth]{img/img_2052_5.png}
	\caption{Consumo Bomba Agua en las fechas: 05/09/2021 - 06/09/2021}
	\label{img_prediccion_sensor2051}
\end{figure}

\tablaSmall{métricas Consumo Bomba Agua}{l c c c c}{métricas}
{ \multicolumn{1}{l}{Rango de fechas} & MSE & RMSE & MAE & R2 \\}{ 
05/09/2021 - 06/09/2021 & 0.056 & 0.237     & 0.176     & -0.891\\
28/08/2021 - 29/08/2021 & 0.04 & 0.2        & 0.153     & -0.417\\
27/08/2021 - 28/08/2021 & 0.068 & 0.261     & 0.186     & -0.474\\
25/08/2021 - 26/08/2021 & 431303.37 & 656.737 & 428.61 & -0.272\\
31/07/2021 - 01/08/2021 & 0.035 & 0.188     & 0.142     & -1.125\\
24/07/2021 - 24/07/2021 & 0.019 & 0.137     & 0.111     & -0.439\\\hline

\textbf{Media}          & \textbf{61614.798} & \textbf{93.965} & \textbf{61.436} & \textbf{-0.516}\\
} 
\newpage

\subsubsection{Pruebas Sensor Presión tubería de agua}

\begin{figure}[h]
	\centering
	\includegraphics[width=1.1\textwidth]{img/img_2051_2.png}
	\caption{Presión tubería de agua en las fechas: 28/08/2021 - 29/08/2021}
	\label{img_2051_2}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=1.1\textwidth]{img/img_2051_6.png}
	\caption{Presión tubería de agua en las fechas: 25/07/2021 - 26/07/2021}
	\label{img_2051_6}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=1.1\textwidth]{img/img_2051_7.png}
	\caption{Presión tubería de agua en las fechas: 31/07/2021 - 01/08/2021}
	\label{img_2051_7}
\end{figure}
\newpage

\tablaSmall{métricas Presión tubería de agua}{l c c c c}{métricas}
{ \multicolumn{1}{l}{Rango de fechas} & MSE & RMSE & MAE & R2 \\}{ 

08/09/2021 - 09/09/2021 & 0.125 & 0.354 & 0.322 & -0.217\\
29/08/2021 - 30/08/2021 & 0.193 & 0.44 & 0.358 & -1.658\\
28/08/2021 - 29/08/2021 & 0.404 & 0.635 & 0.441 & -2.936\\
25/08/2021 - 26/08/2021 & 0.159 & 0.399 & 0.358 & -0.187\\
31/07/2021 - 01/08/2021 & 0.218 & 0.467 & 0.298 & -0.381\\
25/07/2021 - 26/07/2021 & 0.461 & 0.679 & 0.453 & -4.156\\\hline
\textbf{Media}          & \textbf{0.222} & \textbf{0.424} & \textbf{0.318} & \textbf{-1.362}\\
} 

\clearpage
\subsubsection{Pruebas con conjuntos de datos más grandes}
Para probar cómo funcionaría el modelo con un conjunto de datos más amplio, de cinco meses.
Se ha descargado de la página web kaggle un \textit{dataset} que recoge datos procedentes de varios sensores de una bomba de agua. \url{https://www.kaggle.com/nphantawee/pump-sensor-data} 

\begin{figure}[h]
	\centering
	\includegraphics[width=1.1\textwidth]{img/img_dataset1.png}
	\caption{dataset 1}
	\label{img_dataset1}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=1.1\textwidth]{img/img_dataset_3.png}
	\caption{dataset 3}
	\label{img_dataset1}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=1.1\textwidth]{img/img_dataset_4png}
	\caption{dataset 4}
	\label{img_dataset1}
\end{figure}

\tablaSmall{métricas dataset}{l c c c c}{métricas}
{ \multicolumn{1}{l}{} & MSE & RMSE & MAE & R2 \\}{ 

dataset1 & 2.883 & 1.698 & 1.213 & -0.055\\
dataset2 & 1.719 & 1.311 & 1.005 & -0.115\\
dataset3 & 1.613 & 1.270 & 0.982 & -0.287\\
dataset4 & 130.277 & 11.414 & 7.697 & -0.428\\\hline
\textbf{Media}          & \textbf{34.123} & \textbf{3.923} & \textbf{2.724} & \textbf{-0.221}\\
} 

Cómo se puede observar, las pruebas no han sido satisfactorias, al entrenar un \textit{dataset} con un conjunto de datos más amplio los resultados obtenidos no muestran que se haya aplicado un aprendizaje en el momento en el que el modelo deja de entrenar para únicamente predecir.